{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkbkOwRJMX-p"
      },
      "source": [
        "# Behind the pipeline (TensorFlow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpUyr88wMX-w"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baurXLrlMX-y"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsU-iMgCMX-0",
        "outputId": "6e2c3f28-469c-4a01-f52c-cfd02a20a1f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obtFR9A4MX-2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-oZmRHgMX-2",
        "outputId": "4300ef74-97f1-4b87-ecf5-9c43780fbb61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
              "        array([\n",
              "            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
              "            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
              "        ], dtype=int32)>, \n",
              "    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
              "        array([\n",
              "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "            [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "        ], dtype=int32)>\n",
              "}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SU_zlJwMX-3"
      },
      "outputs": [],
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = TFAutoModel.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rgp33JxMX-4",
        "outputId": "5d82bb91-04fe-4ef6-efbe-e5df42d050f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 16, 768)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs = model(inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdjIFms1MX-4"
      },
      "outputs": [],
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bDATehaMX-5",
        "outputId": "1add0a51-0894-4b99-dd8a-5de7b6d0c51f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snEWIxHAMX-6",
        "outputId": "db61e237-1e25-4ed3-b091-6fcf30bfb369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "    array([[-1.5606991,  1.6122842],\n",
              "           [ 4.169231 , -3.3464472]], dtype=float32)>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(outputs.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0t9X9kfMX-6",
        "outputId": "e4bc5cdf-e921-4256-c965-bad267fee8c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tf.Tensor(\n",
              "[[4.01951671e-02 9.59804833e-01]\n",
              " [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVbZBNEGMX-7",
        "outputId": "cefa23c3-3f97-468b-8468-b12361f4b41b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config.id2label"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Behind the pipeline (TensorFlow)",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}